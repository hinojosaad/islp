1. Describe the null hypotheses to which the p-values given in Table 3.4
correspond. Explain what conclusions you can draw based on these
p-values. Your explanation should be phrased in terms of sales, TV,
radio, and newspaper, rather than in terms of the coefficients of the
linear model.

The null hypothesis in 3.4 refers to if there is no relationship between the sales data and respectively the intercept,
TV, radio and newspaper. We coclude that there is a strong evidence that supports that a positive change on the variable Tv or radio implies a positive change on sales. 
Additionally there's strong evidence that suports that on a lack of tv, radio and newspaper we have positive sales. There's not enough evidence for implying a relation 
with newspaper (together with TV and radio). 

2. Carefully explain the differences between the KNN classifier and KNN
regression methods.
The KNN classifier is for predicting a categorical vatiable and the KNN regession is for predicting a quantitative vatiable.
Bassicaly in the fisrt one you take the category that most appear on the K-closests points to the one that you are trying to predict, 
on the second one you take the average of the K-closest points.

3. Suppose we have a data set with five predictors, X1 = GPA, X2 =
IQ, X3 = Level (1 for College and 0 for High School), X4 = Interaction
between GPA and IQ, and X5 = Interaction between GPA and
Level. The response is starting salary after graduation (in thousands
of dollars). Suppose we use least squares to fit the model, and get
betaˆ #0 = 50, betaˆ #1 = 20, betaˆ #2 = 0.07, betaˆ #3 = 35, betaˆ #4 = 0.01, betaˆ #5 = −10.

(a) Which answer is correct, and why?
i. For a fixed value of IQ and GPA, high school graduates earn
more, on average, than college graduates.

Just true if GPA>3.5
ii. For a fixed value of IQ and GPA, college graduates earn
more, on average, than high school graduates.
Just true if GPA<3.5

iii. For a fixed value of IQ and GPA, high school graduates earn
more, on average, than college graduates provided that the
GPA is high enough.
True if GPA > 3.5

iv. For a fixed value of IQ and GPA, college graduates earn
more, on average, than high school graduates provided that
the GPA is high enough.
False, true is iii

(b) Predict the salary of a college graduate with IQ of 110 and a
GPA of 4.0.

50+20*4+.07*110 + 35+.01*4*110-10*4=206.4

(c) True or false: Since the coefficient for the GPA/IQ interaction
term is very small, there is very little evidence of an interaction
effect. Justify your answer.
False, we must perform an hypothesis test with the data to evaluate of accept or reject this coefficient.





4. I collect a set of data (n = 100 observations) containing a single
predictor and a quantitative response. I then fit a linear regression
model to the data, as well as a separate cubic regression, i.e. Y =
#0 + #1X + #2X2 + #3X3 + ".
(a) Suppose that the true relationship between X and Y is linear,
i.e. Y = #0 + #1X + ". Consider the training residual sum of
squares (RSS) for the linear regression, and also the training
RSS for the cubic regression. Would we expect one to be lower
than the other, would we expect them to be the same, or is there
not enough information to tell? Justify your answer.

We would expect than the cubic has a lower RSS since it has more freedom to fit the curve.

(b) Answer (a) using test rather than training RSS.
We expect the test to pass the linear and to reject the cubic since the relation is linear.

(c) Suppose that the true relationship between X and Y is not linear,
but we don’t know how far it is from linear. Consider the training
RSS for the linear regression, and also the training RSS for the
cubic regression. Would we expect one to be lower than the
other, would we expect them to be the same, or is there not
enough information to tell? Justify your answer.

Using a similar argument than (a) we expect cubical to be better

(d) Answer (c) using test rather than training RSS.

Due to its flexibility, it is generally expected that the cubic regression model has lower bias and higher variance than the linear regression model.
 In this exercise, we know that the true relationship is non-linear, but we don't know how far it is from linear.
This means that we don't have any idea about how high the bias of the linear regression model can be.
 If the model is just slightly non-linear, the linear regression will be able to model the data and achieve low bias. T
 hus, we would expect the linear model to have low bias and low variance. This could be enough (or not) to beat the cubic regression model, which is expected to have low bias and high variance.
However, if the true relationship is substantially non-linear, the linear model will not be able to model the data and its bias will be high. 
With high bias and low variance, the linear regression model is beaten by a cubic model without overfitting problems. It will always depend on the bias-variance trade-off and, in general, on the size of the training set and the magnitude of the noise. 
We would need more information to know which model would have lower RSS.

5. Consider the fitted values that result from performing linear regression
without an intercept. In this setting, the ith fitted value takes
the form
ˆyi = xi ˆ #,
where
ˆ # =
>
0n
i=1
xiyi
?
/
>
0n
i!=1
x2i
!
?
. (3.38)
Show that we can write
ˆyi =
0n
i!=1
ai!yi! .
What is ai! ?
Note: We interpret this result by saying that the fitted values from
linear regression are linear combinations of the response values.

6. Using (3.4), argue that in the case of simple linear regression, the
least squares line always passes through the point (¯x, ¯y).

7. It is claimed in the text that in the case of simple linear regression
of Y onto X, the R2 statistic (3.17) is equal to the square of the
correlation between X and Y (3.18). Prove that this is the case. For
simplicity, you may assume that ¯x = ¯y = 0.