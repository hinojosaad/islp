1. Describe the null hypotheses to which the p-values given in Table 3.4
correspond. Explain what conclusions you can draw based on these
p-values. Your explanation should be phrased in terms of sales, TV,
radio, and newspaper, rather than in terms of the coefficients of the
linear model.

The null hypothesis in 3.4 refers to if there is no relationship between the sales data and respectively the intercept,
TV, radio and newspaper. We coclude that there is a strong evidence that supports that a positive change on the variable Tv or radio implies a positive change on sales. 
Additionally there's strong evidence that suports that on a lack of tv, radio and newspaper we have positive sales. There's not enough evidence for implying a relation 
with newspaper (together with TV and radio). 

2. Carefully explain the differences between the KNN classifier and KNN
regression methods.
The KNN classifier is for predicting a categorical vatiable and the KNN regession is for predicting a quantitative vatiable.
Bassicaly in the fisrt one you take the category that most appear on the K-closests points to the one that you are trying to predict, 
on the second one you take the average of the K-closest points.

3. Suppose we have a data set with five predictors, X1 = GPA, X2 =
IQ, X3 = Level (1 for College and 0 for High School), X4 = Interaction
between GPA and IQ, and X5 = Interaction between GPA and
Level. The response is starting salary after graduation (in thousands
of dollars). Suppose we use least squares to fit the model, and get
ˆ #0 = 50, ˆ #1 = 20, ˆ #2 = 0.07, ˆ #3 = 35, ˆ #4 = 0.01, ˆ #5 = −10.
(a) Which answer is correct, and why?
i. For a fixed value of IQ and GPA, high school graduates earn
more, on average, than college graduates.
ii. For a fixed value of IQ and GPA, college graduates earn
more, on average, than high school graduates.
iii. For a fixed value of IQ and GPA, high school graduates earn
more, on average, than college graduates provided that the
GPA is high enough.
iv. For a fixed value of IQ and GPA, college graduates earn
more, on average, than high school graduates provided that
the GPA is high enough.
(b) Predict the salary of a college graduate with IQ of 110 and a
GPA of 4.0.
(c) True or false: Since the coefficient for the GPA/IQ interaction
term is very small, there is very little evidence of an interaction
effect. Justify your answer.
4. I collect a set of data (n = 100 observations) containing a single
predictor and a quantitative response. I then fit a linear regression
model to the data, as well as a separate cubic regression, i.e. Y =
#0 + #1X + #2X2 + #3X3 + ".
(a) Suppose that the true relationship between X and Y is linear,
i.e. Y = #0 + #1X + ". Consider the training residual sum of
squares (RSS) for the linear regression, and also the training
RSS for the cubic regression. Would we expect one to be lower
than the other, would we expect them to be the same, or is there
not enough information to tell? Justify your answer.
(b) Answer (a) using test rather than training RSS.
(c) Suppose that the true relationship between X and Y is not linear,
but we don’t know how far it is from linear. Consider the training
RSS for the linear regression, and also the training RSS for the
cubic regression. Would we expect one to be lower than the
other, would we expect them to be the same, or is there not
enough information to tell? Justify your answer.
(d) Answer (c) using test rather than training RSS.
5. Consider the fitted values that result from performing linear regression
without an intercept. In this setting, the ith fitted value takes
the form
ˆyi = xi ˆ #,
where
ˆ # =
>
0n
i=1
xiyi
?
/
>
0n
i!=1
x2i
!
?
. (3.38)
Show that we can write
ˆyi =
0n
i!=1
ai!yi! .
What is ai! ?
Note: We interpret this result by saying that the fitted values from
linear regression are linear combinations of the response values.

6. Using (3.4), argue that in the case of simple linear regression, the
least squares line always passes through the point (¯x, ¯y).

7. It is claimed in the text that in the case of simple linear regression
of Y onto X, the R2 statistic (3.17) is equal to the square of the
correlation between X and Y (3.18). Prove that this is the case. For
simplicity, you may assume that ¯x = ¯y = 0.